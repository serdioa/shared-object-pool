---
title: "SharedObjectPoolBaseline"
author: "Alexey Serdyuk"
date: "24/10/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# JMH Performance Test for SharedObjectPool

```{r message=FALSE, echo=FALSE}
#
# Load required libraries
#

library(tidyverse) # Efficient data tables.
library(ggplot2) # For drawing charts.
library(grid) # For arranging charts in a grid.
library(kableExtra) # Formatting tables.
```

```{r message=FALSE, echo=FALSE}
# Load benchmark data from the specified file.
readBenchmark <- function(filename) {
    benchmark <- read_csv(filename, skip = 1,
             col_names = c(
                 'Benchmark', 'Mode', 'Threads', 'Samples', 'Score',
                 'ScoreError', 'Unit', 'PooledObjects', 'KeepPct', 'Type'),
             col_types = 'cciiddcidc')
    benchmark$Benchmark <- sub('.*\\.', '', benchmark$Benchmark)
    benchmark
}

# Load benchmark data from all files, collect them in one data table.
benchmark <- bind_rows(
    readBenchmark('SharedObjectPoolBenchmark_1.csv'),
    readBenchmark('SharedObjectPoolBenchmark_2.csv'),
    readBenchmark('SharedObjectPoolBenchmark_4.csv'),
    readBenchmark('SharedObjectPoolBenchmark_6.csv')
)
```

This document compares performance of different implementations of the
`SharedObjectPool` when getting objects from the pool.
The following implementations are tested:

* "sync" is based on standard Java synchronization.
* "locking" is based on `ReadWriteLock`.
* "concurrent" is based on `ConcurrentHashMap` and optimistic locking.

For each implementation, we run tests with a different number of objects in the
pool, as well as with a different probability that the requested object already
exist in the pool (that is, we could return a pooled object instead of adding
a new one to the pool).

The following chart compares performance of implementations for a case when
there is just 1 pooled object. On the left sub-chart the object has to be
created each time when we attempt to get it from the pool. On the right
sub-chart the object is not removed from the pool between method calls and could
be re-used.

```{r message=FALSE, echo=FALSE, fig.width=10, fig.height=4}
#
# Comparing implementations for only 1 object available.
#
ggplot(data = benchmark %>% filter(PooledObjects == 1 & KeepPct != 0.5),
       aes(x = Threads, y = Score, group = Type,
           color = Type)) +
    geom_line() +
    facet_grid(cols = vars(KeepPct)) +
    labs(x = 'Threads') +
    labs(y = 'Duration, ns') +
    labs(title = '1 pooled object')

```

The following chart compares performance of implementations for a case when
there is 1000 pooled objects. On the left sub-chart the object has to be
created each time when we attempt to get it from the pool. On the middle
sub-chart a half of objects has to be created on each access attempt, whereas
a half of objects is kept in the pool and could be re-used. On the right
sub-chart all objects are kept in the pool and could be re-used.

```{r message=FALSE, echo=FALSE, fig.width=10, fig.height=4}
#
# Comparing implementations for 1000 objects available.
#
ggplot(data = benchmark %>% filter(PooledObjects == 1000),
       aes(x = Threads, y = Score, group = Type,
           color = Type)) +
    geom_line() +
    facet_grid(cols = vars(KeepPct)) +
    labs(x = 'Threads') +
    labs(y = 'Duration, ns')
```

The charts shows us:

* Locking implementation scales with a number of concurrent threads much worse
than both synchronized and concurrent implementations. In most cases the locking
implementation is the slowest one when running with 4 threads or more, the only
exception is a very artificial case when the pool contains just 1 object which
is never removed from the pool.

* Whereas concurrent implementation is slower than synchronized implementation
for a small number of objects in the pool, it is faster for a large number
of objects. This is easy to explain: when there is just a few objects in the
pool, a probability that two threads attempt to access the same object is
higher, a locking is required anyway, and the additional overhead of more
complicated locking implementations makes it slower compared to the synchronized
one. On the other hand, when a pool contains many objects and a probability
that two threads will simultaneously attempt to get from the pool the same
object is very low, the concurrent implementation allows different threads
to run in parallel, whereas synchronized implementation could access objects
only one at time.

```{r message=FALSE, echo=FALSE}
if (FALSE){
#
# Comparing concurrent implementation: 
#
ggplot(data = benchmark %>% filter(Type == 'concurrent'),
       aes(x = Threads, y = Score, group = KeepPct,
           color = KeepPct)) +
    geom_line() +
    facet_grid(cols = vars(PooledObjects)) +
    labs(x = 'KeepPct') +
    labs(y = 'Duration, ns')

#
# Comparing locking implementation: 
#
ggplot(data = benchmark %>% filter(Type == 'locking'),
       aes(x = Threads, y = Score, group = KeepPct,
           color = KeepPct)) +
    geom_line() +
    facet_grid(cols = vars(PooledObjects)) +
    labs(x = 'KeepPct') +
    labs(y = 'Duration, ns')

#
# Comparing sync implementation: 
#
ggplot(data = benchmark %>% filter(Type == 'sync'),
       aes(x = Threads, y = Score, group = KeepPct,
           color = KeepPct)) +
    geom_line() +
    facet_grid(cols = vars(PooledObjects)) +
    labs(x = 'KeepPct') +
    labs(y = 'Duration, ns')


benchmark %>% filter(Threads == 1 & Type == 'sync') %>% arrange(KeepPct, PooledObjects)
}
```

